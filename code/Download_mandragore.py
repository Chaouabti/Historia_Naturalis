import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from pathlib import Path

def url_to_soup(query:str, page_num) -> BeautifulSoup:
    """
    Envoie une requ√™te GET √† l'URL de recherche de Mandragore pour le mot-cl√© donn√©.
    Retourne le contenu HTML sous forme d'objet BeautifulSoup.
    
    Param√®tres :
    - query (str) : le mot-cl√© de recherche
    - page_num : num√©ro de page √† r√©cup√©rer (pagination Mandragore)

    Retour :
    - BeautifulSoup : le contenu HTML pars√©, ou None en cas d'erreur r√©seau/HTTP
    """
    
    # URL de recherche Mandragore construite √† partir du mot-cl√© (query) et de la page demand√©e
    url = 'https://mandragore.bnf.fr/recherche/avancee?searchData={"formField"%3A[{"critere"%3A"UD_DESCRIPTEUR"%2C"value"%3A"'+query+'"%2C"exactValue"%3Atrue}]%2C"formType"%3A"UD"}&page='+str(page_num)
    
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        return soup
    
    except requests.exceptions.RequestException as e:
        print(f"Erreur de requ√™te pour l'URL: {url}\n‚Üí {e}")
        return None
    
def get_total_pages(query:str) -> int:
    """
    D√©termine dynamiquement le nombre total de pages de r√©sultats pour une requ√™te Mandragore.
    G√®re les cas d'absence de r√©sultat, ou de structure HTML variable.

    Param√®tres :
    - query (str) : le mot-cl√© de recherche

    Retour :
    - int : nombre de pages de r√©sultats (0 si aucun)
    """

    soup = url_to_soup(query, page_num=1)
    if soup is None:
        print("‚ùå Erreur : impossible de charger la page.")
        return 0
    
    # --- Si aucun r√©sultat de recherche ---
    no_result = soup.find("p", id="error-no-result")
    if no_result:
        print(f"üö´ Aucun r√©sultat trouv√© pour la requ√™te : '{query}'")
        return 0
    
    # --- Si r√©sultats ---
    try: 
        last_page = soup.find('a', title="Derni√®re page")
        if last_page:
            onclick = last_page.get("onclick", "")
            last_page_number = re.search(r"changePagination\('(\d+)',", onclick)
            if last_page_number:
                return int(last_page_number.group(1))
        else:
            # Aucun lien "Derni√®re page" ‚Üí probablement une seule page
            return 1
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'analyse de la pagination : {e}")
        return 1  # Retourner au moins une page par d√©faut

def clean_text(text:str) -> str:
    """
    Nettoie une cha√Æne de texte en supprimant les caract√®res de contr√¥le
    (tabulations, retours √† la ligne, retours chariot) et les espaces multiples.

    Param√®tres :
    - text (str) : cha√Æne de texte brute √† nettoyer

    Retour :
    - str : texte nettoy√© avec un seul espace entre les mots et sans caract√®res parasites
    """
    
    if not text:
        return ''
    # --- Remplacer les tabulations, retours √† la ligne, retour chariot, etc. par un espace ---
    text = re.sub(r'[\t\r\n]+', ' ', text)
    
    # --- Supprimer les espaces en double ou multiples ---
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def retrieve_img_data(query:str, page_num:int) -> list[list[str]]:
    """
    Extrait les donn√©es IIIF et les m√©tadonn√©es associ√©es √† chaque image sur une page de r√©sultats.
    Nettoie le texte tout en conservant les caract√®res sp√©ciaux, et s√©curise chaque extraction.

    Param√®tres :
    - query (str) : mot-cl√© de recherche
    - page_num (int) : num√©ro de page de r√©sultats √† analyser

    Retour :
    - list[list[str]] : liste de lignes contenant
      [img_url, manuscrit, folio, l√©gende, texte enlumin√©, artiste, lieu, date]
    """

    soup = url_to_soup(query, page_num)
    if soup is None:
        print('Impossible d‚Äôanalyser le contenu de la page : https://mandragore.bnf.fr/recherche/avancee?searchData={"formField"%3A[{"critere"%3A"UD_DESCRIPTEUR"%2C"value"%3A"'+query+'"%2C"exactValue"%3Atrue}]%2C"formType"%3A"UD"}&page='+str(page_num))
        return []

    # --- R√©cup√©rer les r√©sultats structur√©s en deux blocs ---
    # Acc√®s √† la ressource image / IIIF
    result_imgs = soup.find_all("div", id="result-img")
    # Acc√®s aux m√©tadonn√©es textuelles
    result_infos = soup.find_all("div", id="result-infos")

    print(f"üîç Images trouv√©es : {len(result_imgs)}")
    print(f"üìù Infos trouv√©es  : {len(result_infos)}")


    all_data = []

    for idx, (img, info) in enumerate(zip(result_imgs, result_infos)):
        try:
            # --- Image URL ---
            img_target = img.find("input", id=lambda x: x and x.startswith("mirador-"))
            img_iiif = img_target.get('value') if img_target else None

            if not img_iiif:
                print(f"‚ö†Ô∏è Image non disponible pour l‚Äôentr√©e #{idx+1}")
                img_url = "Image non disponible"
            else:
                img_url = f'https://gallica.bnf.fr/iiif/{img_iiif}/full/max/0/default.jpg'

                # HIC SUNT DRACONES
                # Zone instable : strat√©gie de fallback r√©seau Gallica ‚Üí Mandragore
                # (d√©sactiv√©e pour l'instant √† cause des limitations de l'API BnF)
                """gallica_url = f'https://gallica.bnf.fr/iiif/{img_iiif}/full/max/0/default.jpg'
                mandragore_url = f'https://mandragore.bnf.fr/iiif/{img_iiif}/full/max/0/default.jpg'

                try:
                    response = requests.get(gallica_url)
                    if response.status_code == 200:
                        img_url = gallica_url
                    else:
                        # Essai Mandragore
                        response_alt = requests.get(mandragore_url)
                        if response_alt.status_code == 200:
                            img_url = mandragore_url
                        else:
                            print(f"‚ö†Ô∏è Image non disponible pour l‚Äôentr√©e #{idx+1}")
                            img_url = "Image non disponible"
                except Exception as e:
                    print(f"‚ùå Erreur r√©seau pour l‚Äôimage #{idx+1} : {e}")
                    img_url = "Image non disponible"""


            # --- Folio + Caption ---
            img_name_tag = info.find_all('a', href=True)
            img_name_raw = img_name_tag[0].text if img_name_tag else ''
            img_name_clean = clean_text(img_name_raw)
            parts = [p.strip() for p in img_name_clean.split(',')]
            img_folio = parts[0].strip() if len(parts) > 0 else ''
            img_caption = parts[1].strip() if len(parts) > 1 else ''

            # --- M√©tadonn√©es manuscrit ---
            ms_name = artist = place = date = ''
            img_data = info.find_all('a', href=True)

            # R√©cup√©ration du nom du manuscrit depuis le <li>
            ms_li = info.find("li", string=lambda s: s and "Manuscrit" in s)
            if ms_li:
                ms_text = ms_li.get_text(" ", strip=True)
                ms_name = re.sub(r"^Manuscrit\s*:\s*", "", ms_text).strip()

            # R√©cup√©ration du bloc contenant artiste, lieu, date
            if len(img_data) > 1:
                img_detail_raw = img_data[1].text.strip()
                lines = img_detail_raw.splitlines()

                cleaned_lines = []
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    if line.startswith("-"):
                        cleaned_lines.append(line.lstrip("-").strip())
                    else:
                        if cleaned_lines:
                            cleaned_lines[-1] += " " + line

                # Attribution des champs si disponibles
                artist = cleaned_lines[0] if len(cleaned_lines) > 0 else ''
                place  = cleaned_lines[1] if len(cleaned_lines) > 1 else ''
                date   = cleaned_lines[2] if len(cleaned_lines) > 2 else ''



            # --- Texte enlumin√© ---
            target_tags = info.find_all('a', href="#")
            if target_tags:
                target_text = clean_text(target_tags[0].get_text(strip=True))
            else:
                target_text = ''

            #  --- Ajout final ---
            all_data.append([img_url, ms_name, img_folio, img_caption, target_text,  artist, place, date])

        except Exception as e:

            print(f"Erreur lors du traitement de l‚Äôentr√©e #{idx} sur la page :" + 'https://mandragore.bnf.fr/recherche/avancee?searchData={"formField"%3A[{"critere"%3A"UD_DESCRIPTEUR"%2C"value"%3A"'+query+'"%2C"exactValue"%3Atrue}]%2C"formType"%3A"UD"}&page='+str(page_num) + f'\n‚Üí {e}')

    return all_data

def browse_results(query: str, output_folder:str) -> None:
    """
    Lance une recherche sur Mandragore, r√©cup√®re toutes les pages de r√©sultats pour un mot-cl√© donn√©,
    extrait les m√©tadonn√©es des images, puis exporte le tout dans un fichier CSV.

    Param√®tres :
    - query (str) : le mot-cl√© de recherche
    - output_folder (str) : dossier de sortie pour le CSV

    Effets :
    - Affiche les progr√®s dans la console
    - Cr√©e un fichier CSV nomm√© 'gallica_data_<query>.csv'
    """
    
    all_data = []

    total_pages = get_total_pages(query)
    if total_pages == 0:
        print(f"Aucun r√©sultat pour la requ√™te : '{query}'. Aucune donn√©e √† exporter.")
        return
    
    print(f"üîç {total_pages} page(s) trouv√©e(s) pour la recherche : {query}")

    # Boucle de pagination (1..total_pages inclus)
    for page_num in range(1, total_pages+1):
        print(f"‚û°Ô∏è  Traitement de la page {page_num}/{total_pages}.")
        
        try:
            # Extraction des lignes (une ligne par image)
            page_data = retrieve_img_data(query, page_num)
            if page_data:
                all_data.extend(page_data)
            else:
                print(f"‚ö†Ô∏è Aucune donn√©e extraite sur la page {page_num}")
        
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement de la page {page_num}: {e}")


    if not all_data:
        print(f"üö´ Aucune donn√©e r√©cup√©r√©e pour la requ√™te '{query}'. Fichier non g√©n√©r√©.")
        return


    # --- Export CSV ---
    Path(output_folder).mkdir(parents=True, exist_ok=True)
    output_file = Path(output_folder) / (f'gallica_data_{query}.csv')
    columns = ['img_url', 'manuscrit', 'folio', 'caption', 'texte',  'artiste', 'lieu', 'date']
    df = pd.DataFrame(all_data, columns=columns)
    df.to_csv(output_file, index=False, encoding='utf-8')

    print(f"‚úÖ {len(all_data)} enregistrement(s) export√©(s) dans '{output_file}")

def download_from_list(list_mandragore_file, output_folder) -> None:
    
    with open(list_mandragore_file, 'r') as kw_file:
        for kw in kw_file:
            browse_results(kw.strip(), output_folder)

list_mandragore_file = None
output_folder = None
download_from_list(list_mandragore_file, output_folder)